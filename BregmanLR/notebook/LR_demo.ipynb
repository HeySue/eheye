{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement two algorithms inspired by Bregman distances presented in 'Logistic Regression, AdaBoost and Bregman Distances' (Schapire et al 2002) and 'Bregman Distance to L1 Regularized Logistic Regression' (Huang and Gupta, 2010). We compare them to two more well known algorithms - Logistic Regression (Newton's Method, No Regularization) and Lasso Regression. \n",
    "\n",
    "We run these 4 algorithms on a variety of datasets and note any patterns on how the nature of the datasets affect the accuracy and convergence rate of the algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Dictionary of datasets, keys are names (string) of datasets, values are 4 tuples: (X_train, X_test, y_train, y_test)\n",
    "datasets = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (70000, 784)\n",
      "Label Data Shape (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Should be 70,000 images (28 by 28 for dimensionality of 784)  \n",
    "print(\"Image Data Shape\" , mnist.data.shape)\n",
    "print(\"Label Data Shape\", mnist.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will focus on binary classification of images with label 0 or 1\n",
    "mnist_relevant_indices = np.where(mnist.target <= 1.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = mnist.data[mnist_relevant_indices]\n",
    "target = mnist.target[mnist_relevant_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "datasets['MNIST'] = train_test_split(data, target, test_size=1/7.0, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Fashion MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fashion_mnist_reader\n",
    "# This requires the data from https://github.com/zalandoresearch/fashion-mnist has been downloaded into data/fashion\n",
    "X_train, y_train = fashion_mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = fashion_mnist_reader.load_mnist('data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filter for labels 0 and 1\n",
    "fmnist_train_data = X_train[np.where(y_train <= 1.0)[0]]\n",
    "fmnist_train_label = y_train[np.where(y_train <= 1.0)[0]]\n",
    "fmnist_test_data = X_test[np.where(y_test <= 1.0)[0]]\n",
    "fmnist_test_label = y_test[np.where(y_test <= 1.0)[0]]\n",
    "\n",
    "datasets['FMNIST'] = (fmnist_train_data, fmnist_test_data, fmnist_train_label, fmnist_test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Ionosphere data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wait for sklearn 0.20.1 release for this to be fixed\n",
    "#from sklearn.datasets import fetch_openml\n",
    "#iono = fetch_openml(data_id=59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (No Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LogitR(X_train, X_test, y_train, y_test):\n",
    "    Logit_model = LogisticRegression(C = 1e6, solver = 'lbfgs', max_iter = 1000)\n",
    "    Logit_model.fit(X_train, y_train)\n",
    "    predictions = Logit_model.predict(X_test)\n",
    "    accuracy = Logit_model.score(X_test, y_test)\n",
    "    weights = np.concatenate([Logit_model.intercept_, Logit_model.coef_[0]])\n",
    "    return weights, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_test_accuracy = LogitR(*datasets['MNIST'])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981060606060606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fmnist_test_accuracy = LogitR(*datasets['FMNIST'])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist_test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lasso Regression (L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LassoR(X_train, X_test, y_train, y_test):\n",
    "    Lasso_model = LassoCV(cv=7)\n",
    "    Lasso_model.fit(X_train, y_train)\n",
    "    predictions = Lasso_model.predict(X_test)\n",
    "    accuracy = Lasso_model.score(X_test, y_test)\n",
    "    weights = np.concatenate([[Lasso_model.intercept_], Lasso_model.coef_])\n",
    "    return weights, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705900434492414"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LassoR(*datasets['MNIST'])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8926456366448151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LassoR(*datasets['FMNIST'])[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bregman Logistic Regression by Schapire et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BregmanLogit(X_train, X_test, y_train, y_test):\n",
    "    from scipy.special import expit as h # Logistic Sigmoid\n",
    "    np.set_printoptions(edgeitems=12)\n",
    "    \n",
    "    # First preprocess the data to include a bias parameter and have targets as +1, -1.\n",
    "    X_train = np.concatenate([np.ones((X_train.shape[0],1)), X_train], axis = 1)\n",
    "    X_test = np.concatenate([np.ones((X_test.shape[0],1)), X_test], axis = 1)\n",
    "    y_train = 2*y_train.astype(int) - 1\n",
    "    y_test = 2*y_test.astype(int) - 1\n",
    "    \n",
    "    n_train_samples, x_dim = X_train.shape\n",
    "    # Train weight vector (Parallel Algorithm, Section 5)\n",
    "    \n",
    "    w = np.zeros(x_dim)\n",
    "    q = 1/2 * np.ones(n_train_samples)\n",
    "    M = X_train * y_train[:, np.newaxis] # Makes M[i] = y[i] * x[i] so M[i][j] = y[i] x[i][j]\n",
    "    \n",
    "    #print(\"M\", M.shape, M, np.count_nonzero(M))\n",
    "    #print(np.sum(M<0))\n",
    "    M_pos = np.multiply(M, M>0)\n",
    "    M_neg = np.multiply(-M, M<0)\n",
    "\n",
    "    iters = 3\n",
    "    for t in range(1,iters):\n",
    "        # Update q\n",
    "        \n",
    "        # Problem - q vanishes very rapidly\n",
    "        \n",
    "        print(\"q start:\", q)\n",
    "        if t==1: \n",
    "            q = 1/2 * np.ones(n_train_samples)\n",
    "        if t>1: \n",
    "            q = np.divide(q, np.multiply(1-q, np.exp(M @ d)) + q)\n",
    "        print(\"q end: \", q)\n",
    "        # Update d\n",
    "        W_pos = q @ M_pos + 1e-3\n",
    "        W_neg = q @ M_neg + 1e-3\n",
    "        #print(\"W_pos\", W_pos.shape, np.count_nonzero(W_pos))\n",
    "        #print(W_pos)\n",
    "        #print(\"W_neg\", W_neg.shape, np.count_nonzero(W_neg))\n",
    "        #print(W_neg)\n",
    "\n",
    "        d = 1/2 * np.log(np.divide(W_pos, W_neg))\n",
    "\n",
    "        w += d\n",
    "    \n",
    "    # Make predictions on test and evaluate accuracy\n",
    "    predictions = np.around(h(X_test @ w))\n",
    "    accuracy = np.mean(y_test.T==predictions)\n",
    "    #predictions = 0\n",
    "    #accuracy = 0\n",
    "    return w, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q start: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "q end:  [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "q start: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "q end:  [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 1.00000000e+000 0.00000000e+000 1.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000 ...\n",
      " 6.10433169e-106 0.00000000e+000 0.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BregmanLogit(*datasets['FMNIST'])[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
