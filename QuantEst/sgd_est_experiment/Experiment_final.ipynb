{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import io, os, sys, types\n",
    "# from IPython import get_ipython\n",
    "# from nbformat import read\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from Distro_generation import get_dataset, get_q_batches, get_q_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distros = ['mix', 'gau_1', 'gau_2', 'exp']\n",
    "stepsizes = ['const', '2_div_sqrt_k', '0.002_div_sqrt_k']\n",
    "\n",
    "tau_vals = [0.1, 0.3, 0.5, 0.9, 0.99]\n",
    "N_g = 12 # N_generation\n",
    "N_s = 10 # N_shuffle\n",
    "\n",
    "# N_q = len(tau_vals)\n",
    "\n",
    "# c_Norm = colors.Normalize(vmin=0, vmax=1)\n",
    "# scalarMap = cmx.ScalarMappable(norm=c_Norm, cmap=plt.get_cmap('cool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if folder exists, if not, then create new empty folders\n",
    "def initialize_folders(fd_lst = ['Frugal_SGD', 'SGD'], main_fd = 'Experiment_results/'):\n",
    "    \n",
    "    for fd in fd_lst:\n",
    "        if not os.path.exists(main_fd+fd):\n",
    "            os.makedirs(main_fd+fd)\n",
    "\n",
    "    sgd_lst = ['distro', 'data_size', 'step_size', 'data_sequence']        \n",
    "    for fd in sgd_lst:\n",
    "        fd_name = main_fd+'SGD/'+fd\n",
    "        if not os.path.exists(fd_name):\n",
    "            os.makedirs(fd_name)\n",
    "\n",
    "initialize_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_settings(distro_lst, datasize_lst, stepsize_lst):\n",
    "    len_lst = [len(distro_lst), len(datasize_lst), len(stepsize_lst)]\n",
    "    if len_lst.count(1) != len(len_lst)-1: \n",
    "#         if len_lst.count(1) == len(len_lst):\n",
    "            \n",
    "        raise Exception(\"Setting inputs are wrong!\")\n",
    "    \n",
    "    N_settings = max((len_lst))\n",
    "    setting_lst = []\n",
    "    for lst in [distro_lst, datasize_lst, stepsize_lst]:\n",
    "        if len(lst)==1: \n",
    "            lst = lst*N_settings\n",
    "        setting_lst.append(lst)\n",
    "        \n",
    "    changed_setting = None\n",
    "    change_lst = ['distro', 'data_size', 'step_size']\n",
    "    for idx, l in enumerate(len_lst):\n",
    "        if l>1: changed_setting = change_lst[idx]\n",
    "    return np.asarray(setting_lst).T, changed_setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_stepsize(k, stepsize, length):\n",
    "#     if stepsize=='const':\n",
    "#         return 1 * np.ones(length)\n",
    "#     elif stepsize=='2_div_sqrt_k':\n",
    "#         return 2/math.sqrt(k)* np.ones(length)\n",
    "#     elif stepsize=='0.002_div_sqrt_k':\n",
    "#         return 0.002/math.sqrt(k) * np.ones(length)\n",
    "#     raise Exception('stepsize parameter is wrong')\n",
    "    \n",
    "    \n",
    "def set_stepsize(k, stepsize):\n",
    "    if stepsize=='const':\n",
    "        return 1\n",
    "    elif stepsize=='2_div_sqrt_k':\n",
    "        return 2/math.sqrt(k)\n",
    "    elif stepsize=='0.002_div_sqrt_k':\n",
    "        return 0.002/math.sqrt(k)\n",
    "    raise Exception('stepsize parameter is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procs(dataset, step_size, tau_lst):\n",
    "    if len(dataset.shape)!= 1: \n",
    "        raise Exception('Dataset for get_procs() of wrong shape:' + str(dataset.shape)+ ', should be 1d array')\n",
    "        \n",
    "    procs = np.zeros((len(tau_lst), dataset.shape[0]))\n",
    "    for idx, tau in enumerate(tau_lst):\n",
    "        q = 0\n",
    "        q_sgd_proc = procs[idx]\n",
    "        # change stepsize\n",
    "        if step_size != 'frugal':\n",
    "            for k, x in enumerate(dataset):\n",
    "#                 if idx==1: print (k, ':', q)\n",
    "                alpha = set_stepsize(k+1, step_size)\n",
    "                if x > q:\n",
    "                    q = q + alpha*tau\n",
    "                else:\n",
    "                    q = q - alpha*(1-tau)\n",
    "                q_sgd_proc[k] = q\n",
    "        \n",
    "        # frugal\n",
    "        else:\n",
    "            rdn_lst = np.random.uniform(0,1, dataset.shape[0])\n",
    "            for k, x in enumerate(dataset):\n",
    "                rdn = rdn_lst[k]\n",
    "                if x > q and rdn > 1-tau:\n",
    "                    q += 1\n",
    "                elif x < q and rdn > tau:\n",
    "                    q -= 1\n",
    "                q_sgd_proc[k] = q\n",
    "    return procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(procs):\n",
    "    if len(procs.shape)!=2:raise Exception('Procs of wrong shape:' + str(procs.shape)+ ', should be 2d array')\n",
    "    \n",
    "    return procs[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_ests(dataset, step_size, tau_lst):\n",
    "\n",
    "    if len(dataset.shape)>2:\n",
    "        raise Exception('Dataset for q_est calculation of wrong shape: {}, should be 1d or 2d array'\n",
    "                        .format(str(dataset.shape)))\n",
    "    if len(dataset.shape)==1:\n",
    "        procs = get_procs(dataset, step_size, tau_lst)\n",
    "        res = get_res(procs)\n",
    "    else:\n",
    "        res = np.zeros((dataset.shape[0], len(tau_lst)))\n",
    "        procs = np.zeros((dataset.shape[0], len(tau_lst), dataset.shape[1]))\n",
    "        for idx, dt in enumerate(dataset):\n",
    "            procs[idx] = get_procs(dt, step_size, tau_lst)\n",
    "            res[idx] = get_res(procs[idx])\n",
    "    return res, procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_dataset('gau_1', 1000, g_test=True) * 50 - 200\n",
    "# print(dataset.shape)\n",
    "\n",
    "# # proc1 = get_procs(dataset, 'const', tau_vals)\n",
    "# ## res1 = get_res(proc1)\n",
    "# # proc2 = get_procs(dataset, 'frugal', tau_vals)\n",
    "# # plt.plot(proc1.T)ad\n",
    "# # plt.plot(proc2.T)\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# res, proc = get_q_ests(dataset, 'const', tau_vals)\n",
    "# print(res)\n",
    "# print(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_e(true, batches, est):\n",
    "    upper = est - batches\n",
    "    bottom = true - batches\n",
    "    return (upper/bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, filename, setting=None):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        if setting is not None: outfile.write('# Setting: {0}\\n'.format(setting))\n",
    "        if len(data.shape) == 1: data = data.reshape(-1, 1)\n",
    "        outfile.write('# Array shape: {0}\\n \\n'.format(data.shape))\n",
    "\n",
    "        for data_slice in data:\n",
    "            np.savetxt(outfile, data_slice, fmt='%-15.8g')\n",
    "            outfile.write('\\n')\n",
    "\n",
    "\n",
    "def write_data_overview(category, setting, tau_lst, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(\"Tested on \"+category+\": \"+str(setting)+\"\\n\") \n",
    "        f.write(str(tau_lst))\n",
    "    \n",
    "# write_data_overview('ca', 'se', tau_vals, \"try.txt\")\n",
    "    \n",
    "def save_data(foldername, file_name, tau_lst, data_dict):\n",
    "    category, setting = file_name[0], file_name[1]    \n",
    "    write_data_overview(category, setting, tau_lst, foldername+str(setting)+\"_\"+\"overview.txt\")\n",
    "\n",
    "    for data_name in data_dict:\n",
    "        print (foldername+str(setting)+\"_\"+data_name+'.txt')\n",
    "        write_data(data_dict[data_name], foldername+str(setting)+\"_\"+data_name+'.txt')\n",
    "        \n",
    "    return\n",
    "\n",
    "# save_data('', ('C', 'S'), tau_vals, {'dataset': np.reshape(np.random.uniform(0, 4, 100), (2, 5, 10))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(changed_setting, distro, datasize, stepsize, s_test):\n",
    "#     print(changed_setting)\n",
    "    if s_test:\n",
    "        return ('Shuffle', True)\n",
    "    setting_dict = {\n",
    "        'distro': ('Distribution', distro),\n",
    "        'data_size': ('Distribution', distro),\n",
    "        'step_size': ('Step size', stepsize),\n",
    "    }\n",
    "    if not setting_dict.get(changed_setting): \n",
    "        raise Exception ('Cannot get file name')\n",
    "    return setting_dict.get(changed_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffled_dataset(dataset, datasize, s_test):\n",
    "    if not s_test: return dataset\n",
    "    \n",
    "    shuffled_dt = np.zeros((N_s, datasize))\n",
    "    for i in range(N_s):\n",
    "        np.random.shuffle(dataset)\n",
    "        shuffled_dt[i] = dataset\n",
    "    dataset = shuffled_dt\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_sgd_compare(folder_name, distro_lst, datasize_lst, stepsize_lst, \n",
    "                         g_test=False, s_test=False, tau_lst=tau_vals, \n",
    "                        ):\n",
    "    \n",
    "    if g_test and s_test: raise Exception(\"g_test and s_test can't both be true\")\n",
    "    \n",
    "    # generate different settings\n",
    "    setting_lst, changed_setting = get_settings(distro_lst, datasize_lst, stepsize_lst,)\n",
    "    print (setting_lst)\n",
    "    \n",
    "    # if only stepsize changes, generate dataset and q_batches\n",
    "    dataset, q_batches = 0, 0\n",
    "    if len(distro_lst)==1 and len(datasize_lst)==1:\n",
    "        dataset = get_dataset(distro_lst[0], datasize_lst[0], g_test)\n",
    "        q_batches = get_q_batches(dataset, tau_lst)\n",
    "        \n",
    "    # for each setting = [distro, datasize, stepsize]\n",
    "    for idx, setting in enumerate(setting_lst):\n",
    "        \n",
    "        # generate all the data\n",
    "        distro, datasize, stepsize = setting[0], int(setting[1]), setting[2]\n",
    "        q_true = get_q_true(distro, tau_lst)\n",
    "        if len(distro_lst)!=1 or len(datasize_lst)!=1:\n",
    "            dataset = get_dataset(distro, datasize, g_test)\n",
    "            q_batches = get_q_batches(dataset, tau_lst)\n",
    "        if s_test: \n",
    "            dataset = get_shuffled_dataset(dataset, datasize, s_test)\n",
    "        q_est_res, q_est_proc = get_q_ests(dataset, stepsize, tau_lst)\n",
    "        E = get_normalized_e(q_true, q_batches, q_est_res)\n",
    "        \n",
    "        data_dict = {\n",
    "            'q_true': q_true,\n",
    "            'q_batches': q_batches,\n",
    "            'q_est_res': q_est_res,\n",
    "            'q_est_proc': q_est_proc,\n",
    "            'E': E\n",
    "        }\n",
    "        # generate charts and tables?\n",
    "        file_name = get_file_name(changed_setting, distro, datasize, stepsize, s_test)\n",
    "        save_data(folder_name, file_name, tau_lst, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_lst = ['distro', 'data_size', 'step_size', 'data_sequence']        \n",
    "\n",
    "def all_sgd_comparisons(sgd_lst, root_folder='SGD'):\n",
    "    \n",
    "    args_dict = {\n",
    "        'distro': (distros, [1000], ['const'], True),\n",
    "        'data_size': (['gau_2'], [100, 1000, 10000], ['const'], True),\n",
    "        'step_size': (['gau_1'], [1000], stepsizes, True),\n",
    "        'data_sequence':(['gau_1', 'gau_1'], [1000], ['const'], False, True),\n",
    "    }\n",
    "    \n",
    "    for t in sgd_lst:\n",
    "        print (t)\n",
    "        folder_name = \"Experiment_results/{}/{}/\".format(root_folder, t)\n",
    "        \n",
    "        args = args_dict.get(t)\n",
    "        distro_lst, datasize_lst, stepsize_lst =  args[0], args[1], args[2]\n",
    "        g_test = args[3]\n",
    "        s_test = False if len(args)<5 else args[4]\n",
    "        tau_lst = tau_vals\n",
    "        print (s_test)\n",
    "        \n",
    "        quantile_sgd_compare(folder_name, distro_lst, datasize_lst, stepsize_lst, g_test, s_test, tau_lst)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_sequence\n",
      "True\n",
      "[['gau_1' '1000' 'const']\n",
      " ['gau_1' '1000' 'const']]\n",
      "Experiment_results/SGD/data_sequence/True_q_true.txt\n",
      "Experiment_results/SGD/data_sequence/True_q_batches.txt\n",
      "Experiment_results/SGD/data_sequence/True_q_est_res.txt\n",
      "Experiment_results/SGD/data_sequence/True_q_est_proc.txt\n",
      "Experiment_results/SGD/data_sequence/True_E.txt\n",
      "Experiment_results/SGD/data_sequence/True_q_true.txt\n",
      "Experiment_results/SGD/data_sequence/True_q_batches.txt\n",
      "Experiment_results/SGD/data_sequence/True_q_est_res.txt\n",
      "Experiment_results/SGD/data_sequence/True_q_est_proc.txt\n",
      "Experiment_results/SGD/data_sequence/True_E.txt\n"
     ]
    }
   ],
   "source": [
    "# Run all functions\n",
    "\n",
    "main_folder = 'SGD'\n",
    "all_sgd_comparisons(['data_sequence'], main_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sgd_frugal_compare(distro_lst, datasize, tau_lst=tau_vals):\n",
    "#     #distro changes, use the biggest datasize, do not shuffle\n",
    "#     for distro in distro_lst:\n",
    "#         q_true = get_q_true(distro, tau_lst)\n",
    "#         dataset = get_dataset(distro, datasize, False)\n",
    "#         q_batches = get_q_batches(dataset, tau_lst)\n",
    "        \n",
    "#         sgd_res, sgd_proc = get_q_ests(dataset, 'const', tau_lst)\n",
    "        \n",
    "#         N_frugal = 20\n",
    "#         frugal_res = np.zeros((N_frugal, len(tau_lst)))\n",
    "#         frugal_proc = np.zeros((N_frugal, len(tau_lst), datasize))\n",
    "#         for i in range(N_frugal):\n",
    "#             frugal_res[i], frugal_proc[i] = get_q_ests(dataset, 'frugal', tau_lst)\n",
    "        \n",
    "#         ax_name = 'Tested on '+distro+' distritbution with '+str(datasize)+' data points'\n",
    "#         fig, lgd = plot_procs(ax_name, tau_vals, q_true, frugal_proc, sgd_proc)\n",
    "#         title = fig.suptitle('Quantile Estimation: Frugal vs SGD')\n",
    "\n",
    "#         fd = \"Experiment_results/Frugal_SGD/\"\n",
    "#         plt.savefig(fd+distro+'.png', bbox_extra_artists=(lgd, title), bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "# sgd_frugal_compare(distros, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "### Always have $q_k = x$ for each x in the data stream\n",
    "\n",
    "When $x - q_k > 0$, we have $l(q_k) = \\tau(x-q_k)$:\n",
    "\\begin{align}\n",
    "q_{k+1} & = q_k - \\frac{l(q_k)}{l'(q_k)} \\\\\n",
    "        & = q_k - \\frac{\\tau(x-q_k)}{-\\tau} \\\\\n",
    "        & = q_k - (- x + q_k) \\\\\n",
    "        & = x\n",
    "\\end{align}\n",
    "\n",
    "Same happens when $x - q_k < 0$\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_results/SGD/data_sequence/True_\n"
     ]
    }
   ],
   "source": [
    "from Plot import plot_charts\n",
    "\n",
    "plot_charts(\"Experiment_results/SGD/data_sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((3,4))\n",
    "a = a.reshape((2,-1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
