{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show quantile estimation with SGD  \"works\"\n",
    "\n",
    "1. Test datasets:\n",
    "    - Mixsture of 5 Gaussians\n",
    "    - Sample of 100k from no.1\n",
    "    - Gausian $\\mu = 2, \\sigma = 18$\n",
    "    - Gausian $\\mu = 0, \\sigma = 0.001$\n",
    "    - Sample 100 from no.1\n",
    "    - Sample 100 from no.3\n",
    "    - Exponential $\\lambda$\n",
    "    - My weird distribution lol\n",
    "    \n",
    "4. Test times:\n",
    "    - 10 $\\times$ dataset generation\n",
    "    - 10 $\\times$ SGD ???\n",
    "    - 10 $\\times$ shuffle (does the order matter?)\n",
    "    \n",
    "2. Q value: 0.1, 0.3, 0.5, 0.9, 0.99 \n",
    "\n",
    "3. Step size: \n",
    "    - $\\alpha_k = 1$\n",
    "    - $\\alpha_k = \\frac{2}{\\sqrt{k}}$\n",
    "    - $\\alpha_k = \\frac{0.002}{\\sqrt{k}}$\n",
    "    - ?\n",
    "    - ?\n",
    "    - Why's the Newton method helpful?\n",
    "       \n",
    "5. Calculate $E = |q_{batch} - q_{sgd}|$\n",
    "\n",
    "6. What's a small value of $E$?\n",
    "\n",
    "7. Investigate the effect of datasize N\n",
    "    - Convergence rate with same $\\alpha_k$?\n",
    "    - Different Q values?\n",
    "    - ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from plt_quantile_comparison.ipynb\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "from plt_quantile_comparison import plot_quantile_shuffles, plot_quantile_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro_list = ['mix_gau', 'gau 1', 'gau 2', 'exp', 'my_distro']\n",
    "\n",
    "q_vals = [0.1, 0.3, 0.5, 0.9, 0.99]\n",
    "N_g = 12 # N_generation\n",
    "N_s = 10 # N_shuffle\n",
    "\n",
    "N_q = len(q_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the inputs are in the form of list\n",
    "# e.g. distro = [mix_gaussian], datasize = [100, 100000], stepsize = [2]\n",
    "def get_n_comp(distro, datasize, stepsize):\n",
    "    print ('get_compared_setting()', distro, datasize, stepsize)\n",
    "    if len(distro) > 1:\n",
    "        if len(datasize)!= 1 or len(stepsize)!=1:\n",
    "            raise Exception('The number of comp_setting is incorrect')\n",
    "        return len(distro)\n",
    "    elif len(datasize) > 1:\n",
    "        if len(stepsize)!=1:\n",
    "            raise Exception('The number of comp_setting is incorrect')        \n",
    "        return len(datasize)\n",
    "    elif len(stepsize) > 1:\n",
    "        print ('step size')\n",
    "        return len(stepsize)\n",
    "    raise Exception('The number of comp_setting is incorrect')\n",
    "\n",
    "def generate_setting_lst(distro, datasize, q_lst, g_test, s_test):\n",
    "    setting_lst = []\n",
    "    if len(distro)>1:\n",
    "        for dis in distro:\n",
    "            setting_lst.append([dis, datasize[0], q_lst, g_test, s_test])\n",
    "    else:\n",
    "        for size in datasize:\n",
    "            setting_lst.append([distro[0], size, q_lst, g_test, s_test])\n",
    "    print (setting_lst)\n",
    "    return setting_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False], [2, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False], [3, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False], [4, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False],\n",
       " [2, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False],\n",
       " [3, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False],\n",
       " [4, 1, [0.1, 0.3, 0.5, 0.9, 0.99], False, False]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_setting_lst([1, 2, 3, 4], [1], q_vals, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and quantile generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distro_list = ['mix_gau', 'gau 1', 'gau 2', 'exp', 'my_distro']\n",
    "\n",
    "def generate_single_dataset(distro, datasize):\n",
    "    if distro == 'gau 1':\n",
    "        return np.random.normal(2, 18, datasize)\n",
    "    elif distro == 'gau 2':\n",
    "        return np.random.normal(0, 0.001, datasize)\n",
    "    elif distro == 'mix':\n",
    "        sizes = np.array([0.3, 0.2, 0.1, 0.15, 0.25]) * datasize\n",
    "        d1 = np.random.normal(2.0, 7.0, int(sizes[0]))\n",
    "        d2 = np.random.normal(0, 3.7, int(sizes[1]))\n",
    "        d3 = np.random.normal(-9, 7, int(sizes[2]))\n",
    "        d4 = np.random.normal(5, 77, int(sizes[3]))\n",
    "        d5 = np.random.normal(-7, 7, int(sizes[4]))\n",
    "        mix_lst = np.append(d1, np.append(d2, np.append(d3, np.append(d4, d5))))\n",
    "        np.random.shuffle(mix_lst)\n",
    "        return mix_lst\n",
    "    elif distro == 'exp':\n",
    "        return np.random.exponential(scale=1, size=datasize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = generate_single_dataset('gau 1', 1000)\n",
    "# data2 = generate_single_dataset('gau 2', 1000)\n",
    "# data_mix = generate_single_dataset('mix', 100000)\n",
    "# data_exp = generate_single_dataset('exp', 1000)\n",
    "\n",
    "# num_bins = 100\n",
    "# plt.hist([data, data2], num_bins, alpha = 0.5, label=['a', 'b'])\n",
    "# plt.hist(data_mix, num_bins, alpha = 0.5, label='mix')\n",
    "# plt.hist(data_exp, num_bins, alpha = 0.5, label='mix')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(distro, datasize, g_test, s_test):\n",
    "#     print ('generate_dataset', distro, datasize, g_test, s_test)\n",
    "#     shape of dataset: 1*Datasize,\n",
    "    if not g_test and not s_test:\n",
    "        return generate_single_dataset(distro, datasize)\n",
    "            \n",
    "    elif g_test and not s_test:\n",
    "        generated_dt = np.zeros((N_g, datasize))\n",
    "        for i in range(N_g):\n",
    "            generated_dt[i] = generate_single_dataset(distro, datasize)\n",
    "        return generated_dt\n",
    "    \n",
    "    elif s_test and not g_test:\n",
    "        shuffled_dt = np.zeros((N_s, datasize))\n",
    "        dt = generate_single_dataset(distro, datasize)\n",
    "        for i in range(N_s): \n",
    "            np.random.shuffle(dt)\n",
    "            shuffled_dt[i] = dt\n",
    "        return shuffled_dt\n",
    "        \n",
    "    dataset = np.zeros((N_g, N_s, datasize))\n",
    "    for gen_id in range(N_g):\n",
    "        dt = generate_single_dataset(distro, datasize)\n",
    "        for shu_id in range(N_s):\n",
    "#             print (gen_id, shu_id)\n",
    "            np.random.shuffle(dt)\n",
    "            dataset[gen_id][shu_id] = dt\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generate_dataset():\n",
    "    distro = 'mix'\n",
    "    datasize = 10000\n",
    "\n",
    "    data_shuffle = generate_dataset(distro, datasize, False, True)\n",
    "    data_gen = generate_dataset(distro, datasize, True, False)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1,sharex=True)\n",
    "    fig.set_size_inches(17, 12)\n",
    "    num_bins = 100\n",
    "    ax1.hist([dt for dt in data_shuffle[:3]], num_bins, alpha = 0.5, label=[str(i) for i in range(20)])\n",
    "    ax1.legend()\n",
    "    ax2.hist([dt for dt in data_gen[:3]], num_bins, alpha = 0.5, label=[str(i) for i in range(20)])\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "# test_generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q_batches_single_dataset(dataset, q_lst):\n",
    "    q_batches = np.zeros(len(q_lst))\n",
    "    for i in range(len(q_lst)):\n",
    "        q_batches[i] = np.percentile(dataset, q_lst[i]*100)\n",
    "    return q_batches\n",
    "\n",
    "\n",
    "def generate_q_batches(dataset, q_lst, g_test, s_test):\n",
    "#     print ('generate_q_batches', dataset, g_test, s_test)\n",
    "    if not g_test:\n",
    "        if s_test:\n",
    "            return generate_q_batches_single_dataset(dataset[0], q_lst)\n",
    "        else: \n",
    "            return generate_q_batches_single_dataset(dataset, q_lst)\n",
    "    else:\n",
    "        N_g = dataset.shape[0]\n",
    "        q_batches = np.zeros((N_g, len(q_lst)))\n",
    "        for i in range(N_g):\n",
    "            if not s_test:\n",
    "                q_batches[i] = generate_q_batches_single_dataset(dataset[i], q_lst)\n",
    "            else:\n",
    "                q_batches[i] = generate_q_batches_single_dataset(dataset[i][0], q_lst)\n",
    "        return q_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reusable_data(distro, datasize, q_lst, g_test, s_test):\n",
    "    print ('generate_reusable_data', (distro, datasize, q_lst, g_test, s_test))\n",
    "    dataset = generate_dataset(distro, datasize, g_test, s_test)\n",
    "    q_batches = generate_q_batches(dataset, q_lst, g_test, s_test)\n",
    "    return dataset, q_batches\n",
    "\n",
    "def generate_q_sgds(dataset, stepsize, q_lst, g_test, s_test):\n",
    "#     q_sgd_proc = generate_q_sgd_proc(dataset, stepsize, q_lst, g_test, s_test)\n",
    "#     q_sgd_res  = generate_q_sgd_res(q_sgd_proc)\n",
    "#     return q_sgd_res, q_sgd_proc \n",
    "    return 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_reusable_data ('exp', 1000000, [0.1, 0.3, 0.5, 0.9, 0.99], True, True)\n",
      "(12, 10, 1000000) \n",
      " 0.9999034936378891 1.0002577204535932 0.6928631958092716\n",
      "[[0.10547028 0.3572514  0.69495467 2.30310341 4.60234149]\n",
      " [0.10567014 0.35626851 0.69251095 2.30341015 4.60100511]\n",
      " [0.10542288 0.35586933 0.6921345  2.29817475 4.60765051]\n",
      " [0.10541072 0.35694838 0.69268425 2.30387933 4.62174621]\n",
      " [0.10504822 0.35628694 0.6919059  2.30136075 4.5826878 ]\n",
      " [0.10565782 0.35598138 0.69180675 2.30430292 4.60398364]\n",
      " [0.10539599 0.35656933 0.69282979 2.30464898 4.6027081 ]\n",
      " [0.10574974 0.35673494 0.69266046 2.30045767 4.61739305]\n",
      " [0.1052071  0.35710159 0.69368236 2.30254107 4.59188449]\n",
      " [0.10570816 0.35670704 0.69321639 2.30363613 4.61720431]\n",
      " [0.10546119 0.35637999 0.69282301 2.30617245 4.59837913]\n",
      " [0.10509111 0.35669309 0.69340076 2.30512209 4.6217217 ]]\n"
     ]
    }
   ],
   "source": [
    "dataset, q_batches = generate_reusable_data('exp', 1000000, q_vals, True, True)\n",
    "print(dataset.shape, '\\n',\n",
    "      dataset.mean(), dataset.std(), np.median(dataset))\n",
    "print(q_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_charts(q_batches, q_sgd_res, q_sgd_proc, g_test, s_test, charts):\n",
    "#     return plts\n",
    "    return 4\n",
    "\n",
    "def draw_tables(q_batches, q_sgd_res, q_sgd_proc, g_test, s_test, charts):\n",
    "#     return tbls\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct experiments on quantile estimation with SGD with regards to different aspects\n",
    "# Experiment results are shown in charts and tables\n",
    "# \n",
    "# Return: None? or charts and figures\n",
    "#\n",
    "# Inputs: \n",
    "#     1. Parameters for the experiments\n",
    "#         - Settings to change: one of {distro, datasize, stepsize} (all elements are lists/dict)\n",
    "#         - Settings to control: the left two of {distro, datasize, stepsize}\n",
    "#                                g_test, s_test\n",
    "#     2. Values to show in the results\n",
    "#         - q_values to be compared\n",
    "#         - charts to be showen in {plt_res, plt_proc, plt_e}\n",
    "#         - tables to be shown in {tbl_res, tbl_proc}\n",
    "\n",
    "def quantile_sgd_compare(distro, datasize, stepsize, \n",
    "                            g_test=False, s_test=False, q_lst=q_vals, \n",
    "                           charts={'plt_res', 'plt_proc', 'plt_e'}, tables={'tbl_res, tbl_proc'}):\n",
    "    dataset, q_batches = 0, 0\n",
    "    N_comp = get_n_comp(distro, datasize, stepsize)\n",
    "    \n",
    "    print (N_comp)\n",
    "    \n",
    "    if len(stepsize)==1:\n",
    "        setting_lst = generate_setting_lst(distro, datasize, q_lst, g_test, s_test)\n",
    "    else:\n",
    "        dataset, q_batches = generate_reusable_data(distro[0], datasize[0], q_lst, g_test, s_test)\n",
    "        print (dataset.shape, q_batches)\n",
    "\n",
    "    # for each round, generate all data and comparison results\n",
    "    for i in range(N_comp):\n",
    "        if len(stepsize)==1:\n",
    "            print (\"generate the {}th dataset and q_batches\".format(i))\n",
    "            lst = setting_lst[i]\n",
    "            distro, datasize, q_lst, g_test, s_test = lst[0], lst[1], lst[2], lst[3], lst[4]\n",
    "            dataset, q_batches = generate_reusable_data(distro, datasize, q_lst, g_test, s_test)\n",
    "            print (dataset.shape, q_batches)\n",
    "            q_sgd_res, q_sgd_proc = generate_q_sgds(dataset, stepsize, q_lst, g_test, s_test)\n",
    "        else:\n",
    "            print ('different q_sgd', i)\n",
    "            q_sgd_res, q_sgd_proc = generate_q_sgds(dataset, stepsize[i], q_lst, g_test, s_test)\n",
    "        plts = draw_charts(q_batches, q_sgd_res, q_sgd_proc, g_test, s_test, charts)\n",
    "        tbls = draw_tables(q_batches, q_sgd_res, q_sgd_proc, g_test, s_test, tables)\n",
    "    # have them together?\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_compared_setting() ['gau 1'] [100] [2, 3, 4]\n",
      "step size\n",
      "3\n",
      "generate_reusable_data ('gau 1', 100, [0.1, 0.3, 0.5, 0.9, 0.99], True, False)\n",
      "(12, 100) [[-23.62333892  -9.19081682  -0.79794357  18.91473365  37.97894605]\n",
      " [-24.13639435  -6.97242004  -0.85398578  18.20687468  41.45425806]\n",
      " [-15.90165152  -6.05168069   2.08176721  26.82313176  42.84113451]\n",
      " [-19.10568246  -7.16856801   2.80144182  23.41060872  35.9572    ]\n",
      " [-19.72066394  -8.11831581   3.88529659  29.36675737  46.28148199]\n",
      " [-19.86753775  -9.86769591   0.65146582  22.76833742  29.78445232]\n",
      " [-16.94340811  -7.50098772  -0.12258783  22.88168449  41.72763182]\n",
      " [-23.39625436  -5.00641602   4.28856299  29.74279972  38.83326316]\n",
      " [-19.97911495  -8.13402831   1.54195416  24.8938768   32.72577811]\n",
      " [-20.07108511  -6.22554944  -0.55848903  28.97152843  43.4278944 ]\n",
      " [-18.99926039  -7.06994621  -0.24780702  21.04037702  39.2583893 ]\n",
      " [-20.28833445  -4.82197652   2.41053216  24.53318208  35.41429514]]\n",
      "different q_sgd 0\n",
      "different q_sgd 1\n",
      "different q_sgd 2\n"
     ]
    }
   ],
   "source": [
    "quantile_sgd_compare(['gau 1'], [100], [2, 3, 4], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt: errorbar\n",
    "# https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/errorbar_subsample.html#sphx-glr-gallery-lines-bars-and-markers-errorbar-subsample-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
